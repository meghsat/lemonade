
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Lemonade Server is a lightweight, open-source local LLM server that allows you to run and manage multiple AI applications on your local machine. It provides a simple CLI for managing applications and supports various LLMs, making it easy to deploy and use AI models locally.">
      
      
      
        <link rel="canonical" href="https://lemonade-server.ai/server/server_spec/">
      
      
        <link rel="prev" href="../server_models/">
      
      
        <link rel="next" href="../server_integration/">
      
      
        
      
      
      <link rel="icon" href="../../assets/favicon.ico">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.1">
    
    
      
        <title>Server Spec - Lemonade Server Documentation</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.484c7ddc.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../assets/extra.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="lightmode" data-md-color-primary="amber" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#lemonade-server-spec" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="https://lemonade-server.ai" title="Lemonade Server Documentation" class="md-header__button md-logo" aria-label="Lemonade Server Documentation" data-md-component="logo">
      
  <img src="../../assets/logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Lemonade Server Documentation
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Server Spec
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="lightmode" data-md-color-primary="amber" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="amber" data-md-color-accent="amber"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/lemonade-sdk/lemonade" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    lemonade-sdk/lemonade
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="https://lemonade-server.ai" title="Lemonade Server Documentation" class="md-nav__button md-logo" aria-label="Lemonade Server Documentation" data-md-component="logo">
      
  <img src="../../assets/logo.png" alt="logo">

    </a>
    Lemonade Server Documentation
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/lemonade-sdk/lemonade" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    lemonade-sdk/lemonade
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Downloading and Getting Started
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../apps/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Supported Applications
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Application Guides
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Application Guides
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../apps/ai-dev-gallery/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    AI Dev Gallery
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../apps/ai-toolkit/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    AI Toolkit
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../apps/anythingLLM/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    AnythingLLM
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../apps/codeGPT/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    CodeGPT
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../apps/continue/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Continue
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../apps/lm-eval/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    LM-Eval-Harness
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../apps/mindcraft/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Mindcraft
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../apps/open-hands/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    OpenHands
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../apps/open-webui/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Open WebUI
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../apps/wut/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Wut
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../lemonade-server-cli/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Lemonade Server CLI Guide
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../concepts/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Understanding local LLM servers
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../server_models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Models List
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    
  
    Server Spec
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    Server Spec
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#endpoints-overview" class="md-nav__link">
    <span class="md-ellipsis">
      
        Endpoints Overview
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Endpoints Overview">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#openai-compatible-endpoints" class="md-nav__link">
    <span class="md-ellipsis">
      
        OpenAI-Compatible Endpoints
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llamacpp-endpoints" class="md-nav__link">
    <span class="md-ellipsis">
      
        llama.cpp Endpoints
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lemonade-specific-endpoints" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lemonade-Specific Endpoints
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#multi-model-support" class="md-nav__link">
    <span class="md-ellipsis">
      
        Multi-Model Support
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Multi-Model Support">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#configuration" class="md-nav__link">
    <span class="md-ellipsis">
      
        Configuration
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model-types" class="md-nav__link">
    <span class="md-ellipsis">
      
        Model Types
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#device-constraints" class="md-nav__link">
    <span class="md-ellipsis">
      
        Device Constraints
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#eviction-policy" class="md-nav__link">
    <span class="md-ellipsis">
      
        Eviction Policy
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#per-model-settings" class="md-nav__link">
    <span class="md-ellipsis">
      
        Per-Model Settings
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#start-the-http-server" class="md-nav__link">
    <span class="md-ellipsis">
      
        Start the HTTP Server
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#openai-compatible-endpoints_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        OpenAI-Compatible Endpoints
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="OpenAI-Compatible Endpoints">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#post-apiv1chatcompletions" class="md-nav__link">
    <span class="md-ellipsis">
      
        POST /api/v1/chat/completions
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="POST /api/v1/chat/completions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parameters
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-request" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example request
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#response-format" class="md-nav__link">
    <span class="md-ellipsis">
      
        Response format
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#post-apiv1completions" class="md-nav__link">
    <span class="md-ellipsis">
      
        POST /api/v1/completions
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="POST /api/v1/completions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parameters
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-request_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example request
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#response-format_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Response format
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#post-apiv1embeddings" class="md-nav__link">
    <span class="md-ellipsis">
      
        POST /api/v1/embeddings
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="POST /api/v1/embeddings">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_2" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parameters
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-request_2" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example request
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#response-format_2" class="md-nav__link">
    <span class="md-ellipsis">
      
        Response format
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#post-apiv1reranking" class="md-nav__link">
    <span class="md-ellipsis">
      
        POST /api/v1/reranking
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="POST /api/v1/reranking">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_3" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parameters
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-request_3" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example request
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#response-format_3" class="md-nav__link">
    <span class="md-ellipsis">
      
        Response format
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#post-apiv1responses" class="md-nav__link">
    <span class="md-ellipsis">
      
        POST /api/v1/responses
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="POST /api/v1/responses">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_4" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parameters
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#streaming-events" class="md-nav__link">
    <span class="md-ellipsis">
      
        Streaming Events
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-request_4" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example request
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#response-format_4" class="md-nav__link">
    <span class="md-ellipsis">
      
        Response format
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#post-apiv1audiotranscriptions" class="md-nav__link">
    <span class="md-ellipsis">
      
        POST /api/v1/audio/transcriptions
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="POST /api/v1/audio/transcriptions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_5" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parameters
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-request_5" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example request
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#response-format_5" class="md-nav__link">
    <span class="md-ellipsis">
      
        Response format
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get-apiv1models" class="md-nav__link">
    <span class="md-ellipsis">
      
        GET /api/v1/models
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="GET /api/v1/models">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_6" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parameters
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-request_6" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example request
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#response-format_6" class="md-nav__link">
    <span class="md-ellipsis">
      
        Response format
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get-apiv1modelsmodel_id" class="md-nav__link">
    <span class="md-ellipsis">
      
        GET /api/v1/models/{model_id}
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="GET /api/v1/models/{model_id}">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_7" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parameters
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-request_7" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example request
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#response-format_7" class="md-nav__link">
    <span class="md-ellipsis">
      
        Response format
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#error-responses" class="md-nav__link">
    <span class="md-ellipsis">
      
        Error responses
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#additional-endpoints" class="md-nav__link">
    <span class="md-ellipsis">
      
        Additional Endpoints
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Additional Endpoints">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#post-apiv1pull" class="md-nav__link">
    <span class="md-ellipsis">
      
        POST /api/v1/pull
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="POST /api/v1/pull">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_8" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parameters
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#streaming-response-streamtrue" class="md-nav__link">
    <span class="md-ellipsis">
      
        Streaming Response (stream=true)
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#post-apiv1delete" class="md-nav__link">
    <span class="md-ellipsis">
      
        POST /api/v1/delete
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="POST /api/v1/delete">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_9" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parameters
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#post-apiv1load" class="md-nav__link">
    <span class="md-ellipsis">
      
        POST /api/v1/load
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="POST /api/v1/load">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_10" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parameters
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#per-model-options" class="md-nav__link">
    <span class="md-ellipsis">
      
        Per-model options
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-requests" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example requests
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#response-format_8" class="md-nav__link">
    <span class="md-ellipsis">
      
        Response format
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#post-apiv1unload" class="md-nav__link">
    <span class="md-ellipsis">
      
        POST /api/v1/unload
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="POST /api/v1/unload">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_11" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parameters
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-requests_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example requests
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#response-format_9" class="md-nav__link">
    <span class="md-ellipsis">
      
        Response format
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get-apiv1health" class="md-nav__link">
    <span class="md-ellipsis">
      
        GET /api/v1/health
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="GET /api/v1/health">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_12" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parameters
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-request_8" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example request
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#response-format_10" class="md-nav__link">
    <span class="md-ellipsis">
      
        Response format
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get-apiv1stats" class="md-nav__link">
    <span class="md-ellipsis">
      
        GET /api/v1/stats
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="GET /api/v1/stats">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_13" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parameters
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-request_9" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example request
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#response-format_11" class="md-nav__link">
    <span class="md-ellipsis">
      
        Response format
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get-apiv1system-info" class="md-nav__link">
    <span class="md-ellipsis">
      
        GET /api/v1/system-info
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="GET /api/v1/system-info">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_14" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parameters
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-request_10" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example request
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#response-format_12" class="md-nav__link">
    <span class="md-ellipsis">
      
        Response format
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../server_integration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Integration Guide
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../faq/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    FAQ Guide
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../contribute/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Contribution Guide
  

    
  </span>
  
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#endpoints-overview" class="md-nav__link">
    <span class="md-ellipsis">
      
        Endpoints Overview
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Endpoints Overview">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#openai-compatible-endpoints" class="md-nav__link">
    <span class="md-ellipsis">
      
        OpenAI-Compatible Endpoints
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#llamacpp-endpoints" class="md-nav__link">
    <span class="md-ellipsis">
      
        llama.cpp Endpoints
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lemonade-specific-endpoints" class="md-nav__link">
    <span class="md-ellipsis">
      
        Lemonade-Specific Endpoints
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#multi-model-support" class="md-nav__link">
    <span class="md-ellipsis">
      
        Multi-Model Support
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Multi-Model Support">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#configuration" class="md-nav__link">
    <span class="md-ellipsis">
      
        Configuration
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model-types" class="md-nav__link">
    <span class="md-ellipsis">
      
        Model Types
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#device-constraints" class="md-nav__link">
    <span class="md-ellipsis">
      
        Device Constraints
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#eviction-policy" class="md-nav__link">
    <span class="md-ellipsis">
      
        Eviction Policy
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#per-model-settings" class="md-nav__link">
    <span class="md-ellipsis">
      
        Per-Model Settings
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#start-the-http-server" class="md-nav__link">
    <span class="md-ellipsis">
      
        Start the HTTP Server
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#openai-compatible-endpoints_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        OpenAI-Compatible Endpoints
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="OpenAI-Compatible Endpoints">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#post-apiv1chatcompletions" class="md-nav__link">
    <span class="md-ellipsis">
      
        POST /api/v1/chat/completions
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="POST /api/v1/chat/completions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parameters
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-request" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example request
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#response-format" class="md-nav__link">
    <span class="md-ellipsis">
      
        Response format
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#post-apiv1completions" class="md-nav__link">
    <span class="md-ellipsis">
      
        POST /api/v1/completions
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="POST /api/v1/completions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parameters
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-request_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example request
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#response-format_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Response format
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#post-apiv1embeddings" class="md-nav__link">
    <span class="md-ellipsis">
      
        POST /api/v1/embeddings
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="POST /api/v1/embeddings">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_2" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parameters
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-request_2" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example request
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#response-format_2" class="md-nav__link">
    <span class="md-ellipsis">
      
        Response format
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#post-apiv1reranking" class="md-nav__link">
    <span class="md-ellipsis">
      
        POST /api/v1/reranking
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="POST /api/v1/reranking">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_3" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parameters
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-request_3" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example request
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#response-format_3" class="md-nav__link">
    <span class="md-ellipsis">
      
        Response format
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#post-apiv1responses" class="md-nav__link">
    <span class="md-ellipsis">
      
        POST /api/v1/responses
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="POST /api/v1/responses">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_4" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parameters
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#streaming-events" class="md-nav__link">
    <span class="md-ellipsis">
      
        Streaming Events
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-request_4" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example request
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#response-format_4" class="md-nav__link">
    <span class="md-ellipsis">
      
        Response format
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#post-apiv1audiotranscriptions" class="md-nav__link">
    <span class="md-ellipsis">
      
        POST /api/v1/audio/transcriptions
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="POST /api/v1/audio/transcriptions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_5" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parameters
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-request_5" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example request
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#response-format_5" class="md-nav__link">
    <span class="md-ellipsis">
      
        Response format
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get-apiv1models" class="md-nav__link">
    <span class="md-ellipsis">
      
        GET /api/v1/models
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="GET /api/v1/models">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_6" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parameters
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-request_6" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example request
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#response-format_6" class="md-nav__link">
    <span class="md-ellipsis">
      
        Response format
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get-apiv1modelsmodel_id" class="md-nav__link">
    <span class="md-ellipsis">
      
        GET /api/v1/models/{model_id}
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="GET /api/v1/models/{model_id}">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_7" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parameters
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-request_7" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example request
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#response-format_7" class="md-nav__link">
    <span class="md-ellipsis">
      
        Response format
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#error-responses" class="md-nav__link">
    <span class="md-ellipsis">
      
        Error responses
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#additional-endpoints" class="md-nav__link">
    <span class="md-ellipsis">
      
        Additional Endpoints
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Additional Endpoints">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#post-apiv1pull" class="md-nav__link">
    <span class="md-ellipsis">
      
        POST /api/v1/pull
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="POST /api/v1/pull">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_8" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parameters
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#streaming-response-streamtrue" class="md-nav__link">
    <span class="md-ellipsis">
      
        Streaming Response (stream=true)
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#post-apiv1delete" class="md-nav__link">
    <span class="md-ellipsis">
      
        POST /api/v1/delete
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="POST /api/v1/delete">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_9" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parameters
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#post-apiv1load" class="md-nav__link">
    <span class="md-ellipsis">
      
        POST /api/v1/load
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="POST /api/v1/load">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_10" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parameters
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#per-model-options" class="md-nav__link">
    <span class="md-ellipsis">
      
        Per-model options
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-requests" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example requests
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#response-format_8" class="md-nav__link">
    <span class="md-ellipsis">
      
        Response format
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#post-apiv1unload" class="md-nav__link">
    <span class="md-ellipsis">
      
        POST /api/v1/unload
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="POST /api/v1/unload">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_11" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parameters
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-requests_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example requests
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#response-format_9" class="md-nav__link">
    <span class="md-ellipsis">
      
        Response format
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get-apiv1health" class="md-nav__link">
    <span class="md-ellipsis">
      
        GET /api/v1/health
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="GET /api/v1/health">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_12" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parameters
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-request_8" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example request
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#response-format_10" class="md-nav__link">
    <span class="md-ellipsis">
      
        Response format
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get-apiv1stats" class="md-nav__link">
    <span class="md-ellipsis">
      
        GET /api/v1/stats
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="GET /api/v1/stats">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_13" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parameters
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-request_9" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example request
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#response-format_11" class="md-nav__link">
    <span class="md-ellipsis">
      
        Response format
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get-apiv1system-info" class="md-nav__link">
    <span class="md-ellipsis">
      
        GET /api/v1/system-info
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="GET /api/v1/system-info">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters_14" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parameters
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-request_10" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example request
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#response-format_12" class="md-nav__link">
    <span class="md-ellipsis">
      
        Response format
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="lemonade-server-spec">Lemonade Server Spec</h1>
<p>The Lemonade Server is a standards-compliant server process that provides an HTTP API to enable integration with other applications.</p>
<p>Lemonade Server currently supports these backends:</p>
<table>
<thead>
<tr>
<th>Backend</th>
<th>Model Format</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/ggml-org/llama.cpp">Llama.cpp</a></td>
<td><code>.GGUF</code></td>
<td>Uses llama.cpp's <code>llama-server</code> backend. More details <a href="#gguf-support">here</a>.</td>
</tr>
<tr>
<td><a href="https://github.com/microsoft/onnxruntime-genai">ONNX Runtime GenAI (OGA)</a></td>
<td><code>.ONNX</code></td>
<td>Uses Lemonade's own <code>ryzenai-server</code> backend.</td>
</tr>
<tr>
<td><a href="https://github.com/FastFlowLM/FastFlowLM">FastFlowLM</a></td>
<td><code>.q4nx</code></td>
<td>Uses FLM's <code>flm serve</code> backend. More details <a href="#fastflowlm-support">here</a>.</td>
</tr>
</tbody>
</table>
<h2 id="endpoints-overview">Endpoints Overview</h2>
<p>The <a href="#openai-compatible-endpoints">key endpoints of the OpenAI API</a> are available.</p>
<p>We are also actively investigating and developing <a href="#lemonade-specific-endpoints">additional endpoints</a> that will improve the experience of local applications.</p>
<h3 id="openai-compatible-endpoints">OpenAI-Compatible Endpoints</h3>
<ul>
<li>POST <code>/api/v1/chat/completions</code> - Chat Completions (messages -&gt; completion)</li>
<li>POST <code>/api/v1/completions</code> - Text Completions (prompt -&gt; completion)</li>
<li>POST <code>/api/v1/embeddings</code> - Embeddings (text -&gt; vector representations)</li>
<li>POST <code>/api/v1/responses</code> - Chat Completions (prompt|messages -&gt; event)</li>
<li>POST <code>/api/v1/audio/transcriptions</code> - Audio Transcription (audio -&gt; text)</li>
<li>GET <code>/api/v1/models</code> - List models available locally</li>
<li>GET <code>/api/v1/models/{model_id}</code> - Retrieve a specific model by ID</li>
</ul>
<h3 id="llamacpp-endpoints">llama.cpp Endpoints</h3>
<p>These endpoints defined by <code>llama.cpp</code> extend the OpenAI-compatible API with additional functionality.</p>
<ul>
<li>POST <code>/api/v1/reranking</code> - Reranking (query + documents -&gt; relevance-scored documents)</li>
</ul>
<h3 id="lemonade-specific-endpoints">Lemonade-Specific Endpoints</h3>
<p>We have designed a set of Lemonade-specific endpoints to enable client applications by extending the existing cloud-focused APIs (e.g., OpenAI). These extensions allow for a greater degree of UI/UX responsiveness in native applications by allowing applications to:</p>
<ul>
<li>Download models at setup time.</li>
<li>Pre-load models at UI-loading-time, as opposed to completion-request time.</li>
<li>Unload models to save memory space.</li>
<li>Understand system resources and state to make dynamic choices.</li>
</ul>
<p>The additional endpoints are:</p>
<ul>
<li>POST <code>/api/v1/pull</code> - Install a model</li>
<li>POST <code>/api/v1/load</code> - Load a model</li>
<li>POST <code>/api/v1/unload</code> - Unload a model</li>
<li>GET <code>/api/v1/health</code> - Check server health</li>
<li>GET <code>/api/v1/stats</code> - Performance statistics from the last request</li>
<li>GET <code>/api/v1/system-info</code> - System information and device enumeration</li>
</ul>
<h2 id="multi-model-support">Multi-Model Support</h2>
<p>Lemonade Server supports loading multiple models simultaneously, allowing you to keep frequently-used models in memory for faster switching. The server uses a Least Recently Used (LRU) cache policy to automatically manage model eviction when limits are reached.</p>
<h3 id="configuration">Configuration</h3>
<p>Use the <code>--max-loaded-models</code> option to specify how many models to keep loaded:</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Load up to 3 LLMs, 2 embedding models, 1 reranking model, and 1 audio model</span>
lemonade-server<span class="w"> </span>serve<span class="w"> </span>--max-loaded-models<span class="w"> </span><span class="m">3</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">1</span>

<span class="c1"># Load up to 5 LLMs (embeddings, reranking, and audio default to 1 each)</span>
lemonade-server<span class="w"> </span>serve<span class="w"> </span>--max-loaded-models<span class="w"> </span><span class="m">5</span>
</code></pre></div>
<p><strong>Default:</strong> <code>1 1 1 1</code> (one model of each type)</p>
<h3 id="model-types">Model Types</h3>
<p>Models are categorized into these types:
- <strong>LLM</strong> - Chat and completion models (default type)
- <strong>Embedding</strong> - Models for generating text embeddings (identified by the <code>embeddings</code> label)
- <strong>Reranking</strong> - Models for document reranking (identified by the <code>reranking</code> label)
- <strong>Audio</strong> - Models for audio transcription using Whisper (identified by the <code>audio</code> label)</p>
<p>Each type has its own independent limit and LRU cache.</p>
<h3 id="device-constraints">Device Constraints</h3>
<ul>
<li><strong>NPU Exclusivity:</strong> Only one model can use the NPU at a time. Loading a new NPU model will evict any existing NPU model regardless of type or limits.</li>
<li><strong>CPU/GPU:</strong> No inherent limits beyond available RAM. Multiple models can coexist on CPU or GPU.</li>
</ul>
<h3 id="eviction-policy">Eviction Policy</h3>
<p>When a model slot is full:
1. The least recently used model of that type is evicted
2. The new model is loaded
3. If loading fails (except file-not-found errors), all models are evicted and the load is retried</p>
<p>Models currently processing inference requests cannot be evicted until they finish.</p>
<h3 id="per-model-settings">Per-Model Settings</h3>
<p>Each model can be loaded with custom settings (context size, llamacpp backend, llamacpp args) via the <code>/api/v1/load</code> endpoint. These per-model settings override the default values set via CLI arguments or environment variables. See the <a href="#post-apiv1load"><code>/api/v1/load</code> endpoint documentation</a> for details.</p>
<p><strong>Setting Priority Order:</strong>
1. Values passed explicitly in <code>/api/v1/load</code> request (highest priority)
2. Values from <code>lemonade-server</code> CLI arguments or environment variables
3. Hardcoded defaults in <code>lemonade-router</code> (lowest priority)</p>
<h2 id="start-the-http-server">Start the HTTP Server</h2>
<blockquote>
<p><strong>NOTE:</strong> This server is intended for use on local systems only. Do not expose the server port to the open internet.</p>
</blockquote>
<p>See the <a href="../">Lemonade Server getting started instructions</a>.</p>
<div class="highlight"><pre><span></span><code>lemonade-server<span class="w"> </span>serve
</code></pre></div>
<h2 id="openai-compatible-endpoints_1">OpenAI-Compatible Endpoints</h2>
<h3 id="post-apiv1chatcompletions"><code>POST /api/v1/chat/completions</code> <sub><img alt="Status" src="https://img.shields.io/badge/status-partially_available-green" /></sub></h3>
<p>Chat Completions API. You provide a list of messages and receive a completion. This API will also load the model if it is not already loaded.</p>
<h4 id="parameters">Parameters</h4>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Required</th>
<th>Description</th>
<th>Status</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>messages</code></td>
<td>Yes</td>
<td>Array of messages in the conversation. Each message should have a <code>role</code> ("user" or "assistant") and <code>content</code> (the message text).</td>
<td><sub><img alt="Status" src="https://img.shields.io/badge/available-green" /></sub></td>
</tr>
<tr>
<td><code>model</code></td>
<td>Yes</td>
<td>The model to use for the completion.</td>
<td><sub><img alt="Status" src="https://img.shields.io/badge/available-green" /></sub></td>
</tr>
<tr>
<td><code>stream</code></td>
<td>No</td>
<td>If true, tokens will be sent as they are generated. If false, the response will be sent as a single message once complete. Defaults to false.</td>
<td><sub><img alt="Status" src="https://img.shields.io/badge/available-green" /></sub></td>
</tr>
<tr>
<td><code>stop</code></td>
<td>No</td>
<td>Up to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence. Can be a string or an array of strings.</td>
<td><sub><img alt="Status" src="https://img.shields.io/badge/available-green" /></sub></td>
</tr>
<tr>
<td><code>logprobs</code></td>
<td>No</td>
<td>Include log probabilities of the output tokens. If true, returns the log probability of each output token. Defaults to false.</td>
<td><sub><img alt="Status" src="https://img.shields.io/badge/not_available-red" /></sub></td>
</tr>
<tr>
<td><code>temperature</code></td>
<td>No</td>
<td>What sampling temperature to use.</td>
<td><sub><img alt="Status" src="https://img.shields.io/badge/available-green" /></sub></td>
</tr>
<tr>
<td><code>repeat_penalty</code></td>
<td>No</td>
<td>Number between 1.0 and 2.0. 1.0 means no penalty. Higher values discourage repetition.</td>
<td><sub><img alt="Status" src="https://img.shields.io/badge/available-green" /></sub></td>
</tr>
<tr>
<td><code>top_k</code></td>
<td>No</td>
<td>Integer that controls the number of top tokens to consider during sampling.</td>
<td><sub><img alt="Status" src="https://img.shields.io/badge/available-green" /></sub></td>
</tr>
<tr>
<td><code>top_p</code></td>
<td>No</td>
<td>Float between 0.0 and 1.0 that controls the cumulative probability of top tokens to consider during nucleus sampling.</td>
<td><sub><img alt="Status" src="https://img.shields.io/badge/available-green" /></sub></td>
</tr>
<tr>
<td><code>tools</code></td>
<td>No</td>
<td>A list of tools the model may call.</td>
<td><sub><img alt="Status" src="https://img.shields.io/badge/available-green" /></sub></td>
</tr>
<tr>
<td><code>max_tokens</code></td>
<td>No</td>
<td>An upper bound for the number of tokens that can be generated for a completion. Mutually exclusive with <code>max_completion_tokens</code>. This value is now deprecated by OpenAI in favor of <code>max_completion_tokens</code></td>
<td><sub><img alt="Status" src="https://img.shields.io/badge/available-green" /></sub></td>
</tr>
<tr>
<td><code>max_completion_tokens</code></td>
<td>No</td>
<td>An upper bound for the number of tokens that can be generated for a completion. Mutually exclusive with <code>max_tokens</code>.</td>
<td><sub><img alt="Status" src="https://img.shields.io/badge/available-green" /></sub></td>
</tr>
</tbody>
</table>
<h4 id="example-request">Example request</h4>
<div class="tabbed-set tabbed-alternate" data-tabs="1:2"><input checked="checked" id="__tabbed_1_1" name="__tabbed_1" type="radio" /><input id="__tabbed_1_2" name="__tabbed_1" type="radio" /><div class="tabbed-labels"><label for="__tabbed_1_1">PowerShell</label><label for="__tabbed_1_2">Bash</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="nb">Invoke-WebRequest</span> <span class="p">`</span>
  <span class="n">-Uri</span> <span class="s2">&quot;http://localhost:8000/api/v1/chat/completions&quot;</span> <span class="p">`</span>
  <span class="n">-Method</span> <span class="n">POST</span> <span class="p">`</span>
  <span class="n">-Headers</span> <span class="p">@{</span> <span class="s2">&quot;Content-Type&quot;</span> <span class="p">=</span> <span class="s2">&quot;application/json&quot;</span> <span class="p">}</span> <span class="p">`</span>
  <span class="n">-Body</span> <span class="s1">&#39;{</span>
<span class="s1">    &quot;model&quot;: &quot;Llama-3.2-1B-Instruct-Hybrid&quot;,</span>
<span class="s1">    &quot;messages&quot;: [</span>
<span class="s1">      {</span>
<span class="s1">        &quot;role&quot;: &quot;user&quot;,</span>
<span class="s1">        &quot;content&quot;: &quot;What is the population of Paris?&quot;</span>
<span class="s1">      }</span>
<span class="s1">    ],</span>
<span class="s1">    &quot;stream&quot;: false</span>
<span class="s1">  }&#39;</span>
</code></pre></div>
</div>
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code>curl<span class="w"> </span>-X<span class="w"> </span>POST<span class="w"> </span>http://localhost:8000/api/v1/chat/completions<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-H<span class="w"> </span><span class="s2">&quot;Content-Type: application/json&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-d<span class="w"> </span><span class="s1">&#39;{</span>
<span class="s1">        &quot;model&quot;: &quot;Llama-3.2-1B-Instruct-Hybrid&quot;,</span>
<span class="s1">        &quot;messages&quot;: [</span>
<span class="s1">          {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;What is the population of Paris?&quot;}</span>
<span class="s1">        ],</span>
<span class="s1">        &quot;stream&quot;: false</span>
<span class="s1">      }&#39;</span>
</code></pre></div>
</div>
</div>
</div>
<h4 id="response-format">Response format</h4>
<div class="tabbed-set tabbed-alternate" data-tabs="2:2"><input checked="checked" id="__tabbed_2_1" name="__tabbed_2" type="radio" /><input id="__tabbed_2_2" name="__tabbed_2" type="radio" /><div class="tabbed-labels"><label for="__tabbed_2_1">Non-streaming responses</label><label for="__tabbed_2_2">Streaming responses</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;0&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;object&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;chat.completion&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;created&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1742927481</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;model&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Llama-3.2-1B-Instruct-Hybrid&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;choices&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[{</span>
<span class="w">    </span><span class="nt">&quot;index&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;message&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;role&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;assistant&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;content&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Paris has a population of approximately 2.2 million people in the city proper.&quot;</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="nt">&quot;finish_reason&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;stop&quot;</span>
<span class="w">  </span><span class="p">}]</span>
<span class="p">}</span>
</code></pre></div>
</div>
<div class="tabbed-block">
<p>For streaming responses, the API returns a stream of server-sent events (however, Open AI recommends using their streaming libraries for parsing streaming responses):</p>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;0&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;object&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;chat.completion.chunk&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;created&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1742927481</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;model&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Llama-3.2-1B-Instruct-Hybrid&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;choices&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[{</span>
<span class="w">    </span><span class="nt">&quot;index&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;delta&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;role&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;assistant&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;content&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Paris&quot;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}]</span>
<span class="p">}</span>
</code></pre></div>
</div>
</div>
</div>
<h3 id="post-apiv1completions"><code>POST /api/v1/completions</code> <sub><img alt="Status" src="https://img.shields.io/badge/status-fully_available-green" /></sub></h3>
<p>Text Completions API. You provide a prompt and receive a completion. This API will also load the model if it is not already loaded.</p>
<h4 id="parameters_1">Parameters</h4>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Required</th>
<th>Description</th>
<th>Status</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>prompt</code></td>
<td>Yes</td>
<td>The prompt to use for the completion.</td>
<td><sub><img alt="Status" src="https://img.shields.io/badge/available-green" /></sub></td>
</tr>
<tr>
<td><code>model</code></td>
<td>Yes</td>
<td>The model to use for the completion.</td>
<td><sub><img alt="Status" src="https://img.shields.io/badge/available-green" /></sub></td>
</tr>
<tr>
<td><code>stream</code></td>
<td>No</td>
<td>If true, tokens will be sent as they are generated. If false, the response will be sent as a single message once complete. Defaults to false.</td>
<td><sub><img alt="Status" src="https://img.shields.io/badge/available-green" /></sub></td>
</tr>
<tr>
<td><code>stop</code></td>
<td>No</td>
<td>Up to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence. Can be a string or an array of strings.</td>
<td><sub><img alt="Status" src="https://img.shields.io/badge/available-green" /></sub></td>
</tr>
<tr>
<td><code>echo</code></td>
<td>No</td>
<td>Echo back the prompt in addition to the completion. Available on non-streaming mode.</td>
<td><sub><img alt="Status" src="https://img.shields.io/badge/available-green" /></sub></td>
</tr>
<tr>
<td><code>logprobs</code></td>
<td>No</td>
<td>Include log probabilities of the output tokens. If true, returns the log probability of each output token. Defaults to false. Only available when <code>stream=False</code>.</td>
<td><sub><img alt="Status" src="https://img.shields.io/badge/available-green" /></sub></td>
</tr>
<tr>
<td><code>temperature</code></td>
<td>No</td>
<td>What sampling temperature to use.</td>
<td><sub><img alt="Status" src="https://img.shields.io/badge/available-green" /></sub></td>
</tr>
<tr>
<td><code>repeat_penalty</code></td>
<td>No</td>
<td>Number between 1.0 and 2.0. 1.0 means no penalty. Higher values discourage repetition.</td>
<td><sub><img alt="Status" src="https://img.shields.io/badge/available-green" /></sub></td>
</tr>
<tr>
<td><code>top_k</code></td>
<td>No</td>
<td>Integer that controls the number of top tokens to consider during sampling.</td>
<td><sub><img alt="Status" src="https://img.shields.io/badge/available-green" /></sub></td>
</tr>
<tr>
<td><code>top_p</code></td>
<td>No</td>
<td>Float between 0.0 and 1.0 that controls the cumulative probability of top tokens to consider during nucleus sampling.</td>
<td><sub><img alt="Status" src="https://img.shields.io/badge/available-green" /></sub></td>
</tr>
<tr>
<td><code>max_tokens</code></td>
<td>No</td>
<td>An upper bound for the number of tokens that can be generated for a completion, including input tokens.</td>
<td><sub><img alt="Status" src="https://img.shields.io/badge/available-green" /></sub></td>
</tr>
</tbody>
</table>
<h4 id="example-request_1">Example request</h4>
<div class="tabbed-set tabbed-alternate" data-tabs="3:2"><input checked="checked" id="__tabbed_3_1" name="__tabbed_3" type="radio" /><input id="__tabbed_3_2" name="__tabbed_3" type="radio" /><div class="tabbed-labels"><label for="__tabbed_3_1">PowerShell</label><label for="__tabbed_3_2">Bash</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="nb">Invoke-WebRequest</span> <span class="n">-Uri</span> <span class="s2">&quot;http://localhost:8000/api/v1/completions&quot;</span> <span class="p">`</span>
  <span class="n">-Method</span> <span class="n">POST</span> <span class="p">`</span>
  <span class="n">-Headers</span> <span class="p">@{</span> <span class="s2">&quot;Content-Type&quot;</span> <span class="p">=</span> <span class="s2">&quot;application/json&quot;</span> <span class="p">}</span> <span class="p">`</span>
  <span class="n">-Body</span> <span class="s1">&#39;{</span>
<span class="s1">    &quot;model&quot;: &quot;Llama-3.2-1B-Instruct-Hybrid&quot;,</span>
<span class="s1">    &quot;prompt&quot;: &quot;What is the population of Paris?&quot;,</span>
<span class="s1">    &quot;stream&quot;: false</span>
<span class="s1">  }&#39;</span>
</code></pre></div>
</div>
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code>curl<span class="w"> </span>-X<span class="w"> </span>POST<span class="w"> </span>http://localhost:8000/api/v1/completions<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-H<span class="w"> </span><span class="s2">&quot;Content-Type: application/json&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-d<span class="w"> </span><span class="s1">&#39;{</span>
<span class="s1">        &quot;model&quot;: &quot;Llama-3.2-1B-Instruct-Hybrid&quot;,</span>
<span class="s1">        &quot;prompt&quot;: &quot;What is the population of Paris?&quot;,</span>
<span class="s1">        &quot;stream&quot;: false</span>
<span class="s1">      }&#39;</span>
</code></pre></div>
</div>
</div>
</div>
<h4 id="response-format_1">Response format</h4>
<p>The following format is used for both streaming and non-streaming responses:</p>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;0&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;object&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;text_completion&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;created&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1742927481</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;model&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Llama-3.2-1B-Instruct-Hybrid&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;choices&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[{</span>
<span class="w">    </span><span class="nt">&quot;index&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;text&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Paris has a population of approximately 2.2 million people in the city proper.&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;finish_reason&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;stop&quot;</span>
<span class="w">  </span><span class="p">}],</span>
<span class="p">}</span>
</code></pre></div>
<h3 id="post-apiv1embeddings"><code>POST /api/v1/embeddings</code> <sub><img alt="Status" src="https://img.shields.io/badge/status-fully_available-green" /></sub></h3>
<p>Embeddings API. You provide input text and receive vector representations (embeddings) that can be used for semantic search, clustering, and similarity comparisons. This API will also load the model if it is not already loaded.</p>
<blockquote>
<p><strong>Note:</strong> This endpoint is only available for models using the <code>llamacpp</code> or <code>flm</code> recipes. ONNX models (OGA recipes) do not support embeddings.</p>
</blockquote>
<h4 id="parameters_2">Parameters</h4>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Required</th>
<th>Description</th>
<th>Status</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>input</code></td>
<td>Yes</td>
<td>The input text or array of texts to embed. Can be a string or an array of strings.</td>
<td><sub><img alt="Status" src="https://img.shields.io/badge/available-green" /></sub></td>
</tr>
<tr>
<td><code>model</code></td>
<td>Yes</td>
<td>The model to use for generating embeddings.</td>
<td><sub><img alt="Status" src="https://img.shields.io/badge/available-green" /></sub></td>
</tr>
<tr>
<td><code>encoding_format</code></td>
<td>No</td>
<td>The format to return embeddings in. Supported values: <code>"float"</code> (default), <code>"base64"</code>.</td>
<td><sub><img alt="Status" src="https://img.shields.io/badge/available-green" /></sub></td>
</tr>
</tbody>
</table>
<h4 id="example-request_2">Example request</h4>
<div class="tabbed-set tabbed-alternate" data-tabs="4:2"><input checked="checked" id="__tabbed_4_1" name="__tabbed_4" type="radio" /><input id="__tabbed_4_2" name="__tabbed_4" type="radio" /><div class="tabbed-labels"><label for="__tabbed_4_1">PowerShell</label><label for="__tabbed_4_2">Bash</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="nb">Invoke-WebRequest</span> <span class="p">`</span>
  <span class="n">-Uri</span> <span class="s2">&quot;http://localhost:8000/api/v1/embeddings&quot;</span> <span class="p">`</span>
  <span class="n">-Method</span> <span class="n">POST</span> <span class="p">`</span>
  <span class="n">-Headers</span> <span class="p">@{</span> <span class="s2">&quot;Content-Type&quot;</span> <span class="p">=</span> <span class="s2">&quot;application/json&quot;</span> <span class="p">}</span> <span class="p">`</span>
  <span class="n">-Body</span> <span class="s1">&#39;{</span>
<span class="s1">    &quot;model&quot;: &quot;nomic-embed-text-v1-GGUF&quot;,</span>
<span class="s1">    &quot;input&quot;: [&quot;Hello, world!&quot;, &quot;How are you?&quot;],</span>
<span class="s1">    &quot;encoding_format&quot;: &quot;float&quot;</span>
<span class="s1">  }&#39;</span>
</code></pre></div>
</div>
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code>curl<span class="w"> </span>-X<span class="w"> </span>POST<span class="w"> </span>http://localhost:8000/api/v1/embeddings<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-H<span class="w"> </span><span class="s2">&quot;Content-Type: application/json&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-d<span class="w"> </span><span class="s1">&#39;{</span>
<span class="s1">        &quot;model&quot;: &quot;nomic-embed-text-v1-GGUF&quot;,</span>
<span class="s1">        &quot;input&quot;: [&quot;Hello, world!&quot;, &quot;How are you?&quot;],</span>
<span class="s1">        &quot;encoding_format&quot;: &quot;float&quot;</span>
<span class="s1">      }&#39;</span>
</code></pre></div>
</div>
</div>
</div>
<h4 id="response-format_2">Response format</h4>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;object&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;list&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;data&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;object&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;embedding&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;index&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;embedding&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="mf">0.0234</span><span class="p">,</span><span class="w"> </span><span class="mf">-0.0567</span><span class="p">,</span><span class="w"> </span><span class="mf">0.0891</span><span class="p">,</span><span class="w"> </span><span class="err">...</span><span class="p">]</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;object&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;embedding&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;index&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;embedding&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="mf">0.0456</span><span class="p">,</span><span class="w"> </span><span class="mf">-0.0678</span><span class="p">,</span><span class="w"> </span><span class="mf">0.1234</span><span class="p">,</span><span class="w"> </span><span class="err">...</span><span class="p">]</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">],</span>
<span class="w">  </span><span class="nt">&quot;model&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;nomic-embed-text-v1-GGUF&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;usage&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;prompt_tokens&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">12</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;total_tokens&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">12</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>
<p><strong>Field Descriptions:</strong></p>
<ul>
<li><code>object</code> - Type of response object, always <code>"list"</code></li>
<li><code>data</code> - Array of embedding objects</li>
<li><code>object</code> - Type of embedding object, always <code>"embedding"</code></li>
<li><code>index</code> - Index position of the input text in the request</li>
<li><code>embedding</code> - Vector representation as an array of floats</li>
<li><code>model</code> - Model identifier used to generate the embeddings</li>
<li><code>usage</code> - Token usage statistics</li>
<li><code>prompt_tokens</code> - Number of tokens in the input</li>
<li><code>total_tokens</code> - Total tokens processed</li>
</ul>
<h3 id="post-apiv1reranking"><code>POST /api/v1/reranking</code> <sub><img alt="Status" src="https://img.shields.io/badge/status-fully_available-green" /></sub></h3>
<p>Reranking API. You provide a query and a list of documents, and receive the documents reordered by their relevance to the query with relevance scores. This is useful for improving search results quality. This API will also load the model if it is not already loaded.</p>
<blockquote>
<p><strong>Note:</strong> This endpoint follows API conventions similar to OpenAI's format but is not part of the official OpenAI API. It is inspired by llama.cpp and other inference server implementations.</p>
<p><strong>Note:</strong> This endpoint is only available for models using the <code>llamacpp</code> recipe. It is not available for FLM or ONNX models.</p>
</blockquote>
<h4 id="parameters_3">Parameters</h4>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Required</th>
<th>Description</th>
<th>Status</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>query</code></td>
<td>Yes</td>
<td>The search query text.</td>
<td><sub><img alt="Status" src="https://img.shields.io/badge/available-green" /></sub></td>
</tr>
<tr>
<td><code>documents</code></td>
<td>Yes</td>
<td>Array of document strings to be reranked.</td>
<td><sub><img alt="Status" src="https://img.shields.io/badge/available-green" /></sub></td>
</tr>
<tr>
<td><code>model</code></td>
<td>Yes</td>
<td>The model to use for reranking.</td>
<td><sub><img alt="Status" src="https://img.shields.io/badge/available-green" /></sub></td>
</tr>
</tbody>
</table>
<h4 id="example-request_3">Example request</h4>
<div class="tabbed-set tabbed-alternate" data-tabs="5:2"><input checked="checked" id="__tabbed_5_1" name="__tabbed_5" type="radio" /><input id="__tabbed_5_2" name="__tabbed_5" type="radio" /><div class="tabbed-labels"><label for="__tabbed_5_1">PowerShell</label><label for="__tabbed_5_2">Bash</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="nb">Invoke-WebRequest</span> <span class="p">`</span>
  <span class="n">-Uri</span> <span class="s2">&quot;http://localhost:8000/api/v1/reranking&quot;</span> <span class="p">`</span>
  <span class="n">-Method</span> <span class="n">POST</span> <span class="p">`</span>
  <span class="n">-Headers</span> <span class="p">@{</span> <span class="s2">&quot;Content-Type&quot;</span> <span class="p">=</span> <span class="s2">&quot;application/json&quot;</span> <span class="p">}</span> <span class="p">`</span>
  <span class="n">-Body</span> <span class="s1">&#39;{</span>
<span class="s1">    &quot;model&quot;: &quot;bge-reranker-v2-m3-GGUF&quot;,</span>
<span class="s1">    &quot;query&quot;: &quot;What is the capital of France?&quot;,</span>
<span class="s1">    &quot;documents&quot;: [</span>
<span class="s1">      &quot;Paris is the capital of France.&quot;,</span>
<span class="s1">      &quot;Berlin is the capital of Germany.&quot;,</span>
<span class="s1">      &quot;Madrid is the capital of Spain.&quot;</span>
<span class="s1">    ]</span>
<span class="s1">  }&#39;</span>
</code></pre></div>
</div>
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code>curl<span class="w"> </span>-X<span class="w"> </span>POST<span class="w"> </span>http://localhost:8000/api/v1/reranking<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-H<span class="w"> </span><span class="s2">&quot;Content-Type: application/json&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-d<span class="w"> </span><span class="s1">&#39;{</span>
<span class="s1">        &quot;model&quot;: &quot;bge-reranker-v2-m3-GGUF&quot;,</span>
<span class="s1">        &quot;query&quot;: &quot;What is the capital of France?&quot;,</span>
<span class="s1">        &quot;documents&quot;: [</span>
<span class="s1">          &quot;Paris is the capital of France.&quot;,</span>
<span class="s1">          &quot;Berlin is the capital of Germany.&quot;,</span>
<span class="s1">          &quot;Madrid is the capital of Spain.&quot;</span>
<span class="s1">        ]</span>
<span class="s1">      }&#39;</span>
</code></pre></div>
</div>
</div>
</div>
<h4 id="response-format_3">Response format</h4>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;model&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;bge-reranker-v2-m3-GGUF&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;object&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;list&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;results&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;index&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;relevance_score&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">8.60673713684082</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;index&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;relevance_score&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">-5.3886260986328125</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;index&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;relevance_score&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">-3.555561065673828</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">],</span>
<span class="w">  </span><span class="nt">&quot;usage&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;prompt_tokens&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">51</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;total_tokens&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">51</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>
<p><strong>Field Descriptions:</strong></p>
<ul>
<li><code>model</code> - Model identifier used for reranking</li>
<li><code>object</code> - Type of response object, always <code>"list"</code></li>
<li><code>results</code> - Array of all documents with relevance scores</li>
<li><code>index</code> - Original index of the document in the input array</li>
<li><code>relevance_score</code> - Relevance score assigned by the model (higher = more relevant)</li>
<li><code>usage</code> - Token usage statistics</li>
<li><code>prompt_tokens</code> - Number of tokens in the input</li>
<li><code>total_tokens</code> - Total tokens processed</li>
</ul>
<blockquote>
<p><strong>Note:</strong> The results are returned in their original input order, not sorted by relevance score. To get documents ranked by relevance, you need to sort the results by <code>relevance_score</code> in descending order on the client side.</p>
</blockquote>
<h3 id="post-apiv1responses"><code>POST /api/v1/responses</code> <sub><img alt="Status" src="https://img.shields.io/badge/status-partially_available-green" /></sub></h3>
<p>Responses API. You provide an input and receive a response. This API will also load the model if it is not already loaded.</p>
<h4 id="parameters_4">Parameters</h4>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Required</th>
<th>Description</th>
<th>Status</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>input</code></td>
<td>Yes</td>
<td>A list of dictionaries or a string input for the model to respond to.</td>
<td><sub><img alt="Status" src="https://img.shields.io/badge/available-green" /></sub></td>
</tr>
<tr>
<td><code>model</code></td>
<td>Yes</td>
<td>The model to use for the response.</td>
<td><sub><img alt="Status" src="https://img.shields.io/badge/available-green" /></sub></td>
</tr>
<tr>
<td><code>max_output_tokens</code></td>
<td>No</td>
<td>The maximum number of output tokens to generate.</td>
<td><sub><img alt="Status" src="https://img.shields.io/badge/available-green" /></sub></td>
</tr>
<tr>
<td><code>temperature</code></td>
<td>No</td>
<td>What sampling temperature to use.</td>
<td><sub><img alt="Status" src="https://img.shields.io/badge/available-green" /></sub></td>
</tr>
<tr>
<td><code>repeat_penalty</code></td>
<td>No</td>
<td>Number between 1.0 and 2.0. 1.0 means no penalty. Higher values discourage repetition.</td>
<td><sub><img alt="Status" src="https://img.shields.io/badge/available-green" /></sub></td>
</tr>
<tr>
<td><code>top_k</code></td>
<td>No</td>
<td>Integer that controls the number of top tokens to consider during sampling.</td>
<td><sub><img alt="Status" src="https://img.shields.io/badge/available-green" /></sub></td>
</tr>
<tr>
<td><code>top_p</code></td>
<td>No</td>
<td>Float between 0.0 and 1.0 that controls the cumulative probability of top tokens to consider during nucleus sampling.</td>
<td><sub><img alt="Status" src="https://img.shields.io/badge/available-green" /></sub></td>
</tr>
<tr>
<td><code>stream</code></td>
<td>No</td>
<td>If true, tokens will be sent as they are generated. If false, the response will be sent as a single message once complete. Defaults to false.</td>
<td><sub><img alt="Status" src="https://img.shields.io/badge/available-green" /></sub></td>
</tr>
</tbody>
</table>
<h4 id="streaming-events">Streaming Events</h4>
<p>The Responses API uses semantic events for streaming. Each event is typed with a predefined schema, so you can listen for events you care about. Our initial implementation only offers support to:</p>
<ul>
<li><code>response.created</code></li>
<li><code>response.output_text.delta</code></li>
<li><code>response.completed</code></li>
</ul>
<p>For a full list of event types, see the <a href="https://platform.openai.com/docs/api-reference/responses-streaming">API reference for streaming</a>.</p>
<h4 id="example-request_4">Example request</h4>
<div class="tabbed-set tabbed-alternate" data-tabs="6:2"><input checked="checked" id="__tabbed_6_1" name="__tabbed_6" type="radio" /><input id="__tabbed_6_2" name="__tabbed_6" type="radio" /><div class="tabbed-labels"><label for="__tabbed_6_1">PowerShell</label><label for="__tabbed_6_2">Bash</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="nb">Invoke-WebRequest</span> <span class="n">-Uri</span> <span class="s2">&quot;http://localhost:8000/api/v1/responses&quot;</span> <span class="p">`</span>
  <span class="n">-Method</span> <span class="n">POST</span> <span class="p">`</span>
  <span class="n">-Headers</span> <span class="p">@{</span> <span class="s2">&quot;Content-Type&quot;</span> <span class="p">=</span> <span class="s2">&quot;application/json&quot;</span> <span class="p">}</span> <span class="p">`</span>
  <span class="n">-Body</span> <span class="s1">&#39;{</span>
<span class="s1">    &quot;model&quot;: &quot;Llama-3.2-1B-Instruct-Hybrid&quot;,</span>
<span class="s1">    &quot;input&quot;: &quot;What is the population of Paris?&quot;,</span>
<span class="s1">    &quot;stream&quot;: false</span>
<span class="s1">  }&#39;</span>
</code></pre></div>
</div>
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code>curl<span class="w"> </span>-X<span class="w"> </span>POST<span class="w"> </span>http://localhost:8000/api/v1/responses<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-H<span class="w"> </span><span class="s2">&quot;Content-Type: application/json&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-d<span class="w"> </span><span class="s1">&#39;{</span>
<span class="s1">        &quot;model&quot;: &quot;Llama-3.2-1B-Instruct-Hybrid&quot;,</span>
<span class="s1">        &quot;input&quot;: &quot;What is the population of Paris?&quot;,</span>
<span class="s1">        &quot;stream&quot;: false</span>
<span class="s1">      }&#39;</span>
</code></pre></div>
</div>
</div>
</div>
<h4 id="response-format_4">Response format</h4>
<div class="tabbed-set tabbed-alternate" data-tabs="7:2"><input checked="checked" id="__tabbed_7_1" name="__tabbed_7" type="radio" /><input id="__tabbed_7_2" name="__tabbed_7" type="radio" /><div class="tabbed-labels"><label for="__tabbed_7_1">Non-streaming responses</label><label for="__tabbed_7_2">Streaming Responses</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;0&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;created_at&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">1746225832.0</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;model&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Llama-3.2-1B-Instruct-Hybrid&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;object&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;response&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;output&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[{</span>
<span class="w">    </span><span class="nt">&quot;id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;0&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;content&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[{</span>
<span class="w">      </span><span class="nt">&quot;annotations&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[],</span>
<span class="w">      </span><span class="nt">&quot;text&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Paris has a population of approximately 2.2 million people in the city proper.&quot;</span>
<span class="w">    </span><span class="p">}]</span>
<span class="w">  </span><span class="p">}]</span>
<span class="p">}</span>
</code></pre></div>
</div>
<div class="tabbed-block">
<p>For streaming responses, the API returns a series of events. Refer to <a href="https://platform.openai.com/docs/guides/streaming-responses?api-mode=responses">OpenAI streaming guide</a> for details.</p>
</div>
</div>
</div>
<h3 id="post-apiv1audiotranscriptions"><code>POST /api/v1/audio/transcriptions</code> <sub><img alt="Status" src="https://img.shields.io/badge/status-partial-yellow" /></sub></h3>
<p>Audio Transcription API. You provide an audio file and receive a text transcription. This API will also load the model if it is not already loaded.</p>
<blockquote>
<p><strong>Note:</strong> This endpoint uses <a href="https://github.com/ggerganov/whisper.cpp">whisper.cpp</a> as the backend. Whisper models are automatically downloaded when first used.</p>
<p><strong>Limitations:</strong> Only <code>wav</code> audio format and <code>json</code> response format are currently supported.</p>
</blockquote>
<h4 id="parameters_5">Parameters</h4>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Required</th>
<th>Description</th>
<th>Status</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>file</code></td>
<td>Yes</td>
<td>The audio file to transcribe. Supported formats: wav.</td>
<td><sub><img alt="Status" src="https://img.shields.io/badge/partial-yellow" /></sub></td>
</tr>
<tr>
<td><code>model</code></td>
<td>Yes</td>
<td>The Whisper model to use for transcription (e.g., <code>Whisper-Tiny</code>, <code>Whisper-Base</code>, <code>Whisper-Small</code>).</td>
<td><sub><img alt="Status" src="https://img.shields.io/badge/available-green" /></sub></td>
</tr>
<tr>
<td><code>language</code></td>
<td>No</td>
<td>The language of the audio (ISO 639-1 code, e.g., <code>en</code>, <code>es</code>, <code>fr</code>). If not specified, Whisper will auto-detect the language.</td>
<td><sub><img alt="Status" src="https://img.shields.io/badge/available-green" /></sub></td>
</tr>
<tr>
<td><code>response_format</code></td>
<td>No</td>
<td>The format of the response. Currently only <code>json</code> is supported.</td>
<td><sub><img alt="Status" src="https://img.shields.io/badge/available-green" /></sub></td>
</tr>
</tbody>
</table>
<h4 id="example-request_5">Example request</h4>
<div class="tabbed-set tabbed-alternate" data-tabs="8:2"><input checked="checked" id="__tabbed_8_1" name="__tabbed_8" type="radio" /><input id="__tabbed_8_2" name="__tabbed_8" type="radio" /><div class="tabbed-labels"><label for="__tabbed_8_1">Windows</label><label for="__tabbed_8_2">Linux/macOS</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code>curl<span class="w"> </span>-X<span class="w"> </span>POST<span class="w"> </span>http://localhost:8000/api/v1/audio/transcriptions<span class="w"> </span>^
<span class="w">  </span>-F<span class="w"> </span><span class="s2">&quot;file=@C:\path\to\audio.wav&quot;</span><span class="w"> </span>^
<span class="w">  </span>-F<span class="w"> </span><span class="s2">&quot;model=Whisper-Tiny&quot;</span>
</code></pre></div>
</div>
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code>curl<span class="w"> </span>-X<span class="w"> </span>POST<span class="w"> </span>http://localhost:8000/api/v1/audio/transcriptions<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-F<span class="w"> </span><span class="s2">&quot;file=@/path/to/audio.wav&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-F<span class="w"> </span><span class="s2">&quot;model=Whisper-Tiny&quot;</span>
</code></pre></div>
</div>
</div>
</div>
<h4 id="response-format_5">Response format</h4>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;text&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Hello, this is a sample transcription of the audio file.&quot;</span>
<span class="p">}</span>
</code></pre></div>
<p><strong>Field Descriptions:</strong></p>
<ul>
<li><code>text</code> - The transcribed text from the audio file</li>
</ul>
<h3 id="get-apiv1models"><code>GET /api/v1/models</code> <sub><img alt="Status" src="https://img.shields.io/badge/status-fully_available-green" /></sub></h3>
<p>Returns a list of models available on the server in an OpenAI-compatible format. Each model object includes extended fields like <code>checkpoint</code>, <code>recipe</code>, <code>size</code>, <code>downloaded</code>, and <code>labels</code>.</p>
<p>By default, only models available locally (downloaded) are shown, matching OpenAI API behavior.</p>
<h4 id="parameters_6">Parameters</h4>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Required</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>show_all</code></td>
<td>No</td>
<td>If set to <code>true</code>, returns all models from the catalog including those not yet downloaded. Defaults to <code>false</code>.</td>
</tr>
</tbody>
</table>
<h4 id="example-request_6">Example request</h4>
<div class="highlight"><pre><span></span><code><span class="c1"># Show only downloaded models (OpenAI-compatible)</span>
curl<span class="w"> </span>http://localhost:8000/api/v1/models

<span class="c1"># Show all models including not-yet-downloaded (extended usage)</span>
curl<span class="w"> </span>http://localhost:8000/api/v1/models?show_all<span class="o">=</span><span class="nb">true</span>
</code></pre></div>
<h4 id="response-format_6">Response format</h4>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;object&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;list&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;data&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Qwen3-0.6B-GGUF&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;created&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1744173590</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;object&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;model&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;owned_by&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;lemonade&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;checkpoint&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;unsloth/Qwen3-0.6B-GGUF:Q4_0&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;recipe&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;llamacpp&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;size&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">0.38</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;downloaded&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;suggested&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;labels&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;reasoning&quot;</span><span class="p">]</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Gemma-3-4b-it-GGUF&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;created&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1744173590</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;object&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;model&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;owned_by&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;lemonade&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;checkpoint&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;ggml-org/gemma-3-4b-it-GGUF:Q4_K_M&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;recipe&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;llamacpp&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;size&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">3.61</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;downloaded&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;suggested&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;labels&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;hot&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;vision&quot;</span><span class="p">]</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">]</span>
<span class="p">}</span>
</code></pre></div>
<p><strong>Field Descriptions:</strong></p>
<ul>
<li><code>object</code> - Type of response object, always <code>"list"</code></li>
<li><code>data</code> - Array of model objects with the following fields:</li>
<li><code>id</code> - Model identifier (used for loading and inference requests)</li>
<li><code>created</code> - Unix timestamp of when the model entry was created</li>
<li><code>object</code> - Type of object, always <code>"model"</code></li>
<li><code>owned_by</code> - Owner of the model, always <code>"lemonade"</code></li>
<li><code>checkpoint</code> - Full checkpoint identifier on Hugging Face</li>
<li><code>recipe</code> - Backend/device recipe used to load the model (e.g., <code>"oga-cpu"</code>, <code>"oga-hybrid"</code>, <code>"llamacpp"</code>, <code>"flm"</code>)</li>
<li><code>size</code> - Model size in GB (omitted for models without size information)</li>
<li><code>downloaded</code> - Boolean indicating if the model is downloaded and available locally</li>
<li><code>suggested</code> - Boolean indicating if the model is recommended for general use</li>
<li><code>labels</code> - Array of tags describing the model (e.g., <code>"hot"</code>, <code>"reasoning"</code>, <code>"vision"</code>, <code>"embeddings"</code>, <code>"reranking"</code>, <code>"coding"</code>, <code>"tool-calling"</code>)</li>
</ul>
<h3 id="get-apiv1modelsmodel_id"><code>GET /api/v1/models/{model_id}</code> <sub><img alt="Status" src="https://img.shields.io/badge/status-fully_available-green" /></sub></h3>
<p>Retrieve a specific model by its ID. Returns the same model object format as the list endpoint above.</p>
<h4 id="parameters_7">Parameters</h4>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Required</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>model_id</code></td>
<td>Yes</td>
<td>The ID of the model to retrieve. Must match one of the model IDs from the <a href="../server_models/">models list</a>.</td>
</tr>
</tbody>
</table>
<h4 id="example-request_7">Example request</h4>
<div class="highlight"><pre><span></span><code>curl<span class="w"> </span>http://localhost:8000/api/v1/models/Qwen3-0.6B-GGUF
</code></pre></div>
<h4 id="response-format_7">Response format</h4>
<p>Returns a single model object with the same fields as described in the <a href="#get-apiv1models">models list endpoint</a> above.</p>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Qwen3-0.6B-GGUF&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;created&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1744173590</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;object&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;model&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;owned_by&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;lemonade&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;checkpoint&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;unsloth/Qwen3-0.6B-GGUF:Q4_0&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;recipe&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;llamacpp&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;size&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">0.38</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;downloaded&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;suggested&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;labels&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;reasoning&quot;</span><span class="p">]</span>
<span class="p">}</span>
</code></pre></div>
<h4 id="error-responses">Error responses</h4>
<p>If the model is not found, the endpoint returns a 404 error:</p>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;error&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;message&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Model Llama-3.2-1B-Instruct-Hybrid has not been found&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;not_found&quot;</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>
<h2 id="additional-endpoints">Additional Endpoints</h2>
<h3 id="post-apiv1pull"><code>POST /api/v1/pull</code> <sub><img alt="Status" src="https://img.shields.io/badge/status-fully_available-green" /></sub></h3>
<p>Register and install models for use with Lemonade Server.</p>
<h4 id="parameters_8">Parameters</h4>
<p>The Lemonade Server built-in model registry has a collection of model names that can be pulled and loaded. The <code>pull</code> endpoint can install any registered model, and it can also register-then-install any model available on Hugging Face.</p>
<p><strong>Common Parameters</strong></p>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Required</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>stream</code></td>
<td>No</td>
<td>If <code>true</code>, returns Server-Sent Events (SSE) with download progress. Defaults to <code>false</code>.</td>
</tr>
</tbody>
</table>
<p><strong>Install a Model that is Already Registered</strong></p>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Required</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>model_name</code></td>
<td>Yes</td>
<td><a href="../server_models/">Lemonade Server model name</a> to install.</td>
</tr>
</tbody>
</table>
<p>Example request:</p>
<div class="highlight"><pre><span></span><code>curl<span class="w"> </span>-X<span class="w"> </span>POST<span class="w"> </span>http://localhost:8000/api/v1/pull<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-H<span class="w"> </span><span class="s2">&quot;Content-Type: application/json&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-d<span class="w"> </span><span class="s1">&#39;{</span>
<span class="s1">    &quot;model_name&quot;: &quot;Qwen2.5-0.5B-Instruct-CPU&quot;</span>
<span class="s1">  }&#39;</span>
</code></pre></div>
<p>Response format:</p>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;status&quot;</span><span class="p">:</span><span class="s2">&quot;success&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;message&quot;</span><span class="p">:</span><span class="s2">&quot;Installed model: Qwen2.5-0.5B-Instruct-CPU&quot;</span>
<span class="p">}</span>
</code></pre></div>
<p>In case of an error, the status will be <code>error</code> and the message will contain the error message.</p>
<p><strong>Register and Install a Model</strong></p>
<p>Registration will place an entry for that model in the <code>user_models.json</code> file, which is located in the user's Lemonade cache (default: <code>~/.cache/lemonade</code>). Then, the model will be installed. Once the model is registered and installed, it will show up in the <code>models</code> endpoint alongside the built-in models and can be loaded.</p>
<p>The <code>recipe</code> field defines which software framework and device will be used to load and run the model. For more information on OGA and Hugging Face recipes, see the <a href="../../lemonade_api/">Lemonade API README</a>. For information on GGUF recipes, see <a href="#gguf-support">llamacpp</a>.</p>
<blockquote>
<p>Note: the <code>model_name</code> for registering a new model must use the <code>user</code> namespace, to prevent collisions with built-in models. For example, <code>user.Phi-4-Mini-GGUF</code>.</p>
</blockquote>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Required</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>model_name</code></td>
<td>Yes</td>
<td>Namespaced <a href="../server_models/">Lemonade Server model name</a> to register and install.</td>
</tr>
<tr>
<td><code>checkpoint</code></td>
<td>Yes</td>
<td>HuggingFace checkpoint to install.</td>
</tr>
<tr>
<td><code>recipe</code></td>
<td>Yes</td>
<td>Lemonade API recipe to load the model with.</td>
</tr>
<tr>
<td><code>reasoning</code></td>
<td>No</td>
<td>Whether the model is a reasoning model, like DeepSeek (default: false). Adds 'reasoning' label.</td>
</tr>
<tr>
<td><code>vision</code></td>
<td>No</td>
<td>Whether the model has vision capabilities for processing images (default: false). Adds 'vision' label.</td>
</tr>
<tr>
<td><code>embedding</code></td>
<td>No</td>
<td>Whether the model is an embedding model (default: false). Adds 'embeddings' label.</td>
</tr>
<tr>
<td><code>reranking</code></td>
<td>No</td>
<td>Whether the model is a reranking model (default: false). Adds 'reranking' label.</td>
</tr>
<tr>
<td><code>mmproj</code></td>
<td>No</td>
<td>Multimodal Projector (mmproj) file to use for vision models.</td>
</tr>
</tbody>
</table>
<p>Example request:</p>
<div class="highlight"><pre><span></span><code>curl<span class="w"> </span>-X<span class="w"> </span>POST<span class="w"> </span>http://localhost:8000/api/v1/pull<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-H<span class="w"> </span><span class="s2">&quot;Content-Type: application/json&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-d<span class="w"> </span><span class="s1">&#39;{</span>
<span class="s1">    &quot;model_name&quot;: &quot;user.Phi-4-Mini-GGUF&quot;,</span>
<span class="s1">    &quot;checkpoint&quot;: &quot;unsloth/Phi-4-mini-instruct-GGUF:Q4_K_M&quot;,</span>
<span class="s1">    &quot;recipe&quot;: &quot;llamacpp&quot;</span>
<span class="s1">  }&#39;</span>
</code></pre></div>
<p>Response format:</p>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;status&quot;</span><span class="p">:</span><span class="s2">&quot;success&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;message&quot;</span><span class="p">:</span><span class="s2">&quot;Installed model: user.Phi-4-Mini-GGUF&quot;</span>
<span class="p">}</span>
</code></pre></div>
<p>In case of an error, the status will be <code>error</code> and the message will contain the error message.</p>
<h4 id="streaming-response-streamtrue">Streaming Response (stream=true)</h4>
<p>When <code>stream=true</code>, the endpoint returns Server-Sent Events with real-time download progress:</p>
<div class="highlight"><pre><span></span><code>event: progress
data: {&quot;file&quot;:&quot;model.gguf&quot;,&quot;file_index&quot;:1,&quot;total_files&quot;:2,&quot;bytes_downloaded&quot;:1073741824,&quot;bytes_total&quot;:2684354560,&quot;percent&quot;:40}

event: progress
data: {&quot;file&quot;:&quot;config.json&quot;,&quot;file_index&quot;:2,&quot;total_files&quot;:2,&quot;bytes_downloaded&quot;:1024,&quot;bytes_total&quot;:1024,&quot;percent&quot;:100}

event: complete
data: {&quot;file_index&quot;:2,&quot;total_files&quot;:2,&quot;percent&quot;:100}
</code></pre></div>
<p><strong>Event Types:</strong></p>
<table>
<thead>
<tr>
<th>Event</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>progress</code></td>
<td>Sent during download with current file and byte progress</td>
</tr>
<tr>
<td><code>complete</code></td>
<td>Sent when all files are downloaded successfully</td>
</tr>
<tr>
<td><code>error</code></td>
<td>Sent if download fails, with <code>error</code> field containing the message</td>
</tr>
</tbody>
</table>
<h3 id="post-apiv1delete"><code>POST /api/v1/delete</code> <sub><img alt="Status" src="https://img.shields.io/badge/status-fully_available-green" /></sub></h3>
<p>Delete a model by removing it from local storage. If the model is currently loaded, it will be unloaded first.</p>
<h4 id="parameters_9">Parameters</h4>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Required</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>model_name</code></td>
<td>Yes</td>
<td><a href="../server_models/">Lemonade Server model name</a> to delete.</td>
</tr>
</tbody>
</table>
<p>Example request:</p>
<div class="highlight"><pre><span></span><code>curl<span class="w"> </span>-X<span class="w"> </span>POST<span class="w"> </span>http://localhost:8000/api/v1/delete<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-H<span class="w"> </span><span class="s2">&quot;Content-Type: application/json&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-d<span class="w"> </span><span class="s1">&#39;{</span>
<span class="s1">    &quot;model_name&quot;: &quot;Qwen2.5-0.5B-Instruct-CPU&quot;</span>
<span class="s1">  }&#39;</span>
</code></pre></div>
<p>Response format:</p>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;status&quot;</span><span class="p">:</span><span class="s2">&quot;success&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;message&quot;</span><span class="p">:</span><span class="s2">&quot;Deleted model: Qwen2.5-0.5B-Instruct-CPU&quot;</span>
<span class="p">}</span>
</code></pre></div>
<p>In case of an error, the status will be <code>error</code> and the message will contain the error message.</p>
<p><a id="post-apiv1load"></a></p>
<h3 id="post-apiv1load"><code>POST /api/v1/load</code> <sub><img alt="Status" src="https://img.shields.io/badge/status-fully_available-green" /></sub></h3>
<p>Explicitly load a registered model into memory. This is useful to ensure that the model is loaded before you make a request. Installs the model if necessary.</p>
<h4 id="parameters_10">Parameters</h4>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Required</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>model_name</code></td>
<td>Yes</td>
<td><a href="../server_models/">Lemonade Server model name</a> to load.</td>
</tr>
<tr>
<td><code>ctx_size</code></td>
<td>No</td>
<td>Context size for the model. Overrides the default value for this model.</td>
</tr>
<tr>
<td><code>llamacpp_backend</code></td>
<td>No</td>
<td>LlamaCpp backend to use (<code>vulkan</code>, <code>rocm</code>, <code>metal</code> or <code>cpu</code>). Only applies to llamacpp models.</td>
</tr>
<tr>
<td><code>llamacpp_args</code></td>
<td>No</td>
<td>Custom arguments to pass to llama-server. The following are NOT allowed: <code>-m</code>, <code>--port</code>, <code>--ctx-size</code>, <code>-ngl</code>.</td>
</tr>
</tbody>
</table>
<p><strong>Setting Priority:</strong></p>
<p>When loading a model, settings are applied in this priority order:
1. Values explicitly passed in the <code>load</code> request (highest priority)
2. Per-model values configurable in <code>recipe_options.json</code> (see below for details)
3. Values set via <code>lemonade-server</code> CLI arguments or environment variables
4. Default hardcoded values in <code>lemonade-router</code> (lowest priority)</p>
<h4 id="per-model-options">Per-model options</h4>
<p>You can configure a default <code>ctx_size</code>, <code>llamacpp_backend</code> and <code>llamacpp_args</code> on a per-model basis. To do this you need to create a file called <code>recipe_options.json</code> in the user's Lemonade cache (default: <code>~/.cache/lemonade</code>). An example <code>recipe_options.json</code> file follows:</p>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;user.Qwen2.5-Coder-1.5B-Instruct&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;ctx_size&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">16384</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;llamacpp_backend&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;vulkan&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;llamacpp_args&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;-np 2 -kvu&quot;</span>
<span class="w">  </span><span class="p">},</span>
<span class="w">  </span><span class="nt">&quot;Qwen3-Coder-30B-A3B-Instruct-GGUF&quot;</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;llamacpp_backend&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;rocm&quot;</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>
<p>Note that user models (i.e. those defined in <code>user_models.json</code>) must include the "user." prefix in their name when referencing them in <code>recipe_options.json</code>.</p>
<h4 id="example-requests">Example requests</h4>
<p>Basic load:</p>
<div class="highlight"><pre><span></span><code>curl<span class="w"> </span>-X<span class="w"> </span>POST<span class="w"> </span>http://localhost:8000/api/v1/load<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-H<span class="w"> </span><span class="s2">&quot;Content-Type: application/json&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-d<span class="w"> </span><span class="s1">&#39;{</span>
<span class="s1">    &quot;model_name&quot;: &quot;Qwen2.5-0.5B-Instruct-CPU&quot;</span>
<span class="s1">  }&#39;</span>
</code></pre></div>
<p>Load with custom settings:</p>
<div class="highlight"><pre><span></span><code>curl<span class="w"> </span>-X<span class="w"> </span>POST<span class="w"> </span>http://localhost:8000/api/v1/load<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-H<span class="w"> </span><span class="s2">&quot;Content-Type: application/json&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-d<span class="w"> </span><span class="s1">&#39;{</span>
<span class="s1">    &quot;model_name&quot;: &quot;llama-3.2-3b-instruct-GGUF&quot;,</span>
<span class="s1">    &quot;ctx_size&quot;: 8192,</span>
<span class="s1">    &quot;llamacpp_backend&quot;: &quot;rocm&quot;,</span>
<span class="s1">    &quot;llamacpp_args&quot;: &quot;--flash-attn on --no-mmap&quot;</span>
<span class="s1">  }&#39;</span>
</code></pre></div>
<h4 id="response-format_8">Response format</h4>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;status&quot;</span><span class="p">:</span><span class="s2">&quot;success&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;message&quot;</span><span class="p">:</span><span class="s2">&quot;Loaded model: Qwen2.5-0.5B-Instruct-CPU&quot;</span>
<span class="p">}</span>
</code></pre></div>
<p>In case of an error, the status will be <code>error</code> and the message will contain the error message.</p>
<h3 id="post-apiv1unload"><code>POST /api/v1/unload</code> <sub><img alt="Status" src="https://img.shields.io/badge/status-fully_available-green" /></sub></h3>
<p>Explicitly unload a model from memory. This is useful to free up memory while still leaving the server process running (which takes minimal resources but a few seconds to start).</p>
<h4 id="parameters_11">Parameters</h4>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Required</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>model_name</code></td>
<td>No</td>
<td>Name of the specific model to unload. If not provided, all loaded models will be unloaded.</td>
</tr>
</tbody>
</table>
<h4 id="example-requests_1">Example requests</h4>
<p>Unload a specific model:</p>
<div class="highlight"><pre><span></span><code>curl<span class="w"> </span>-X<span class="w"> </span>POST<span class="w"> </span>http://localhost:8000/api/v1/unload<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-H<span class="w"> </span><span class="s2">&quot;Content-Type: application/json&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-d<span class="w"> </span><span class="s1">&#39;{&quot;model_name&quot;: &quot;Llama-3.2-1B-Instruct-Hybrid&quot;}&#39;</span>
</code></pre></div>
<p>Unload all models:</p>
<div class="highlight"><pre><span></span><code>curl<span class="w"> </span>-X<span class="w"> </span>POST<span class="w"> </span>http://localhost:8000/api/v1/unload
</code></pre></div>
<h4 id="response-format_9">Response format</h4>
<p>Success response:</p>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;status&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;success&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;message&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Model unloaded successfully&quot;</span>
<span class="p">}</span>
</code></pre></div>
<p>Error response (model not found):</p>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;status&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;error&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;message&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Model not found: Llama-3.2-1B-Instruct-Hybrid&quot;</span>
<span class="p">}</span>
</code></pre></div>
<p>In case of an error, the status will be <code>error</code> and the message will contain the error message.</p>
<h3 id="get-apiv1health"><code>GET /api/v1/health</code> <sub><img alt="Status" src="https://img.shields.io/badge/status-fully_available-green" /></sub></h3>
<p>Check the health of the server. This endpoint returns information about loaded models.</p>
<h4 id="parameters_12">Parameters</h4>
<p>This endpoint does not take any parameters.</p>
<h4 id="example-request_8">Example request</h4>
<div class="highlight"><pre><span></span><code>curl<span class="w"> </span>http://localhost:8000/api/v1/health
</code></pre></div>
<h4 id="response-format_10">Response format</h4>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;status&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;ok&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;checkpoint_loaded&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;amd/Llama-3.2-1B-Instruct-awq-g128-int4-asym-fp16-onnx-hybrid&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;model_loaded&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Llama-3.2-1B-Instruct-Hybrid&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;all_models_loaded&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;model_name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Llama-3.2-1B-Instruct-Hybrid&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;checkpoint&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;amd/Llama-3.2-1B-Instruct-awq-g128-int4-asym-fp16-onnx-hybrid&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;last_use&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">1732123456.789</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;llm&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;device&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;gpu npu&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;backend_url&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;http://127.0.0.1:8001/v1&quot;</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;model_name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;nomic-embed-text-v1-GGUF&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;checkpoint&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;nomic-ai/nomic-embed-text-v1-GGUF:Q4_K_S&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;last_use&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">1732123450.123</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;embedding&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;device&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;gpu&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;backend_url&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;http://127.0.0.1:8002/v1&quot;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">],</span>
<span class="w">  </span><span class="nt">&quot;max_models&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;llm&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;embedding&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;reranking&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>
<p><strong>Field Descriptions:</strong></p>
<ul>
<li><code>status</code> - Server health status, always <code>"ok"</code></li>
<li><code>checkpoint_loaded</code> - Checkpoint identifier of the most recently accessed model</li>
<li><code>model_loaded</code> - Model name of the most recently accessed model</li>
<li><code>all_models_loaded</code> - Array of all currently loaded models with details:</li>
<li><code>model_name</code> - Name of the loaded model</li>
<li><code>checkpoint</code> - Full checkpoint identifier</li>
<li><code>last_use</code> - Unix timestamp of last access (load or inference)</li>
<li><code>type</code> - Model type: <code>"llm"</code>, <code>"embedding"</code>, or <code>"reranking"</code></li>
<li><code>device</code> - Space-separated device list: <code>"cpu"</code>, <code>"gpu"</code>, <code>"npu"</code>, or combinations like <code>"gpu npu"</code></li>
<li><code>backend_url</code> - URL of the backend server process handling this model (useful for debugging)</li>
<li><code>max_models</code> - Maximum number of models that can be loaded simultaneously (set via <code>--max-loaded-models</code>):</li>
<li><code>llm</code> - Maximum LLM/chat models</li>
<li><code>embedding</code> - Maximum embedding models</li>
<li><code>reranking</code> - Maximum reranking models</li>
</ul>
<h3 id="get-apiv1stats"><code>GET /api/v1/stats</code> <sub><img alt="Status" src="https://img.shields.io/badge/status-fully_available-green" /></sub></h3>
<p>Performance statistics from the last request.</p>
<h4 id="parameters_13">Parameters</h4>
<p>This endpoint does not take any parameters.</p>
<h4 id="example-request_9">Example request</h4>
<div class="highlight"><pre><span></span><code>curl<span class="w"> </span>http://localhost:8000/api/v1/stats
</code></pre></div>
<h4 id="response-format_11">Response format</h4>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;time_to_first_token&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">2.14</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;tokens_per_second&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">33.33</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;input_tokens&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">128</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;output_tokens&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">5</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;decode_token_times&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="mf">0.01</span><span class="p">,</span><span class="w"> </span><span class="mf">0.02</span><span class="p">,</span><span class="w"> </span><span class="mf">0.03</span><span class="p">,</span><span class="w"> </span><span class="mf">0.04</span><span class="p">,</span><span class="w"> </span><span class="mf">0.05</span><span class="p">],</span>
<span class="w">  </span><span class="nt">&quot;prompt_tokens&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">9</span>
<span class="p">}</span>
</code></pre></div>
<p><strong>Field Descriptions:</strong></p>
<ul>
<li><code>time_to_first_token</code> - Time in seconds until the first token was generated</li>
<li><code>tokens_per_second</code> - Generation speed in tokens per second</li>
<li><code>input_tokens</code> - Number of tokens processed</li>
<li><code>output_tokens</code> - Number of tokens generated</li>
<li><code>decode_token_times</code> - Array of time taken for each generated token</li>
<li><code>prompt_tokens</code> - Total prompt tokens including cached tokens</li>
</ul>
<h3 id="get-apiv1system-info"><code>GET /api/v1/system-info</code> <sub><img alt="Status" src="https://img.shields.io/badge/status-fully_available-green" /></sub></h3>
<p>System information endpoint that provides complete hardware details and device enumeration.</p>
<h4 id="parameters_14">Parameters</h4>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Required</th>
<th>Description</th>
<th>Status</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>verbose</code></td>
<td>No</td>
<td>Include detailed system information. When <code>false</code> (default), returns essential information (OS, processor, memory, devices). When <code>true</code>, includes additional details like Python packages and extended system information.</td>
<td><sub><img alt="Status" src="https://img.shields.io/badge/available-green" /></sub></td>
</tr>
</tbody>
</table>
<h4 id="example-request_10">Example request</h4>
<div class="tabbed-set tabbed-alternate" data-tabs="9:2"><input checked="checked" id="__tabbed_9_1" name="__tabbed_9" type="radio" /><input id="__tabbed_9_2" name="__tabbed_9" type="radio" /><div class="tabbed-labels"><label for="__tabbed_9_1">Basic system information</label><label for="__tabbed_9_2">Detailed system information</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code>curl<span class="w"> </span><span class="s2">&quot;http://localhost:8000/api/v1/system-info&quot;</span>
</code></pre></div>
</div>
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code>curl<span class="w"> </span><span class="s2">&quot;http://localhost:8000/api/v1/system-info?verbose=true&quot;</span>
</code></pre></div>
</div>
</div>
</div>
<h4 id="response-format_12">Response format</h4>
<div class="tabbed-set tabbed-alternate" data-tabs="10:1"><input checked="checked" id="__tabbed_10_1" name="__tabbed_10" type="radio" /><div class="tabbed-labels"><label for="__tabbed_10_1">Basic response (verbose=false)</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;OS Version&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Windows-10-10.0.26100-SP0&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;Processor&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;AMD Ryzen AI 9 HX 375 w/ Radeon 890M&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;Physical Memory&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;32.0 GB&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;devices&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;cpu&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;AMD Ryzen AI 9 HX 375 w/ Radeon 890M&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;cores&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">12</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;threads&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">24</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;available&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="nt">&quot;amd_igpu&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;AMD Radeon(TM) 890M Graphics&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;memory_mb&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">512</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;driver_version&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">32.0.12010.10001</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;available&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="nt">&quot;amd_dgpu&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[],</span>
<span class="w">    </span><span class="nt">&quot;npu&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;AMD NPU&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;driver_version&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;32.0.203.257&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;power_mode&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Default&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;available&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>
</div>
</div>
</div>
<h1 id="debugging">Debugging</h1>
<p>To help debug the Lemonade server, you can use the <code>--log-level</code> parameter to control the verbosity of logging information. The server supports multiple logging levels that provide increasing amounts of detail about server operations.</p>
<div class="highlight"><pre><span></span><code>lemonade-server serve --log-level [level]
</code></pre></div>
<p>Where <code>[level]</code> can be one of:</p>
<ul>
<li><strong>critical</strong>: Only critical errors that prevent server operation.</li>
<li><strong>error</strong>: Error conditions that might allow continued operation.</li>
<li><strong>warning</strong>: Warning conditions that should be addressed.</li>
<li><strong>info</strong>: (Default) General informational messages about server operation.</li>
<li><strong>debug</strong>: Detailed diagnostic information for troubleshooting, including metrics such as input/output token counts, Time To First Token (TTFT), and Tokens Per Second (TPS).</li>
<li><strong>trace</strong>: Very detailed tracing information, including everything from debug level plus all input prompts.</li>
</ul>
<h1 id="gguf-support">GGUF Support</h1>
<p>The <code>llama-server</code> backend works with Lemonade's suggested <code>*-GGUF</code> models, as well as any .gguf model from Hugging Face. Windows, Ubuntu Linux, and macOS are supported. Details:
- Lemonade Server wraps <code>llama-server</code> with support for the <code>lemonade-server</code> CLI, client web app, and endpoints (e.g., <code>models</code>, <code>pull</code>, <code>load</code>, etc.).
  - The <code>chat/completions</code>, <code>completions</code>, <code>embeddings</code>, and <code>reranking</code> endpoints are supported.
  - The <code>embeddings</code> endpoint requires embedding-specific models (e.g., nomic-embed-text models).
  - The <code>reranking</code> endpoint requires reranker-specific models (e.g., bge-reranker models).
  - <code>responses</code> is not supported at this time.
- A single Lemonade Server process can seamlessly switch between GGUF, ONNX, and FastFlowLM models.
  - Lemonade Server will attempt to load models onto GPU with Vulkan first, and if that doesn't work it will fall back to CPU.
  - From the end-user's perspective, OGA vs. GGUF should be completely transparent: they wont be aware of whether the built-in server or <code>llama-server</code> is serving their model.</p>
<h2 id="installing-gguf-models">Installing GGUF Models</h2>
<p>To install an arbitrary GGUF from Hugging Face, open the Lemonade web app by navigating to http://localhost:8000 in your web browser, click the Model Management tab, and use the Add a Model form.</p>
<h2 id="platform-support-matrix">Platform Support Matrix</h2>
<table>
<thead>
<tr>
<th>Platform</th>
<th>GPU Acceleration</th>
<th>CPU Architecture</th>
</tr>
</thead>
<tbody>
<tr>
<td>Windows</td>
<td> Vulkan, ROCm</td>
<td> x64</td>
</tr>
<tr>
<td>Ubuntu</td>
<td> Vulkan, ROCm</td>
<td> x64</td>
</tr>
<tr>
<td>macOS</td>
<td> Metal</td>
<td> Apple Silicon</td>
</tr>
<tr>
<td>Other Linux</td>
<td>* Vulkan</td>
<td>* x64</td>
</tr>
</tbody>
</table>
<p>*Other Linux distributions may work but are not officially supported.</p>
<h1 id="fastflowlm-support">FastFlowLM Support</h1>
<p>Similar to the <a href="#gguf-support">llama-server support</a>, Lemonade can also route OpenAI API requests to a FastFlowLM <code>flm serve</code> backend.</p>
<p>The <code>flm serve</code> backend works with Lemonade's suggested <code>*-FLM</code> models, as well as any model mentioned in <code>flm list</code>. Windows is the only supported operating system. Details:
- Lemonade Server wraps <code>flm serve</code> with support for the <code>lemonade-server</code> CLI, client web app, and all Lemonade custom endpoints (e.g., <code>pull</code>, <code>load</code>, etc.).
  - OpenAI API endpoints supported: <code>models</code>, <code>chat/completions</code> (streaming), and <code>embeddings</code>.
  - The <code>embeddings</code> endpoint requires embedding-specific models supported by FLM.
- A single Lemonade Server process can seamlessly switch between FLM, OGA, and GGUF models.</p>
<h2 id="installing-flm-models">Installing FLM Models</h2>
<p>To install an arbitrary FLM model:
1. <code>flm list</code> to view the supported models.
1. Open the Lemonade web app by navigating to http://localhost:8000 in your web browser, click the Model Management tab, and use the Add a Model form.
1. Use the model name from <code>flm list</code> as the "checkpoint name" in the Add a Model form and select "flm" as the recipe.</p>
<!--This file was originally licensed under Apache 2.0. It has been modified.
Modifications Copyright (c) 2025 AMD-->












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../server_models/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Models List">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                Models List
              </div>
            </div>
          </a>
        
        
          
          <a href="../server_integration/" class="md-footer__link md-footer__link--next" aria-label="Next: Integration Guide">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                Integration Guide
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2025 AMD. All rights reserved.
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        
<div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://www.youtube.com/@AMDDevCentral" target="_blank" rel="noopener" title="www.youtube.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M23.498 6.186a3.02 3.02 0 0 0-2.122-2.136C19.505 3.545 12 3.545 12 3.545s-7.505 0-9.377.505A3.02 3.02 0 0 0 .502 6.186C0 8.07 0 12 0 12s0 3.93.502 5.814a3.02 3.02 0 0 0 2.122 2.136c1.871.505 9.376.505 9.376.505s7.505 0 9.377-.505a3.02 3.02 0 0 0 2.122-2.136C24 15.93 24 12 24 12s0-3.93-.502-5.814M9.545 15.568V8.432L15.818 12z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://github.com/lemonade-sdk/lemonade" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://discord.gg/5xXzkMu8Zk" target="_blank" rel="noopener" title="discord.gg" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.317 4.37a19.8 19.8 0 0 0-4.885-1.515.074.074 0 0 0-.079.037c-.21.375-.444.864-.608 1.25a18.3 18.3 0 0 0-5.487 0 13 13 0 0 0-.617-1.25.08.08 0 0 0-.079-.037A19.7 19.7 0 0 0 3.677 4.37a.1.1 0 0 0-.032.027C.533 9.046-.32 13.58.099 18.057a.08.08 0 0 0 .031.057 19.9 19.9 0 0 0 5.993 3.03.08.08 0 0 0 .084-.028c.462-.63.874-1.295 1.226-1.994a.076.076 0 0 0-.041-.106 13 13 0 0 1-1.872-.892.077.077 0 0 1-.008-.128 10 10 0 0 0 .372-.292.07.07 0 0 1 .077-.01c3.928 1.793 8.18 1.793 12.062 0a.07.07 0 0 1 .078.01c.12.098.246.198.373.292a.077.077 0 0 1-.006.127 12.3 12.3 0 0 1-1.873.892.077.077 0 0 0-.041.107c.36.698.772 1.362 1.225 1.993a.08.08 0 0 0 .084.028 19.8 19.8 0 0 0 6.002-3.03.08.08 0 0 0 .032-.054c.5-5.177-.838-9.674-3.549-13.66a.06.06 0 0 0-.031-.03M8.02 15.33c-1.182 0-2.157-1.085-2.157-2.419 0-1.333.956-2.419 2.157-2.419 1.21 0 2.176 1.096 2.157 2.42 0 1.333-.956 2.418-2.157 2.418m7.975 0c-1.183 0-2.157-1.085-2.157-2.419 0-1.333.955-2.419 2.157-2.419 1.21 0 2.176 1.096 2.157 2.42 0 1.333-.946 2.418-2.157 2.418"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../..", "features": ["navigation.footer", "navigation.tracking", "navigation.expand", "navigation.top", "content.code.annotate", "content.code.copy"], "search": "../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.79ae519e.min.js"></script>
      
        <script src="../../assets/carousel.js"></script>
      
    
  </body>
</html>